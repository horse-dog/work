#### 持久数据的可靠性

- RAID: 把多个 (不可靠的) 磁盘虚拟成一块非常可靠且性能极高的虚拟磁盘

#### RAID 0

- 原理：将文件数据分散存储到多个硬盘。

- 在进行读写时，实现了多个物理硬盘的并行、提高读写速度。

- 缺点：一旦某块硬盘损坏、数据将难以恢复。

#### RAID 1

- 原理：镜像存储，两块硬盘互为备份，存储的内容完全相同。

- 读取性能翻倍，写入性能不变。

- 提供数据冗余，如果其中一块数据丢失，可以通过另一块还原。

- 缺点：磁盘利用率低、成本高

#### RAID 5

- 如果我们有100块盘，但假设不会有两块盘同时损坏，使用RAID 5保证数据的可靠性。

- 99块盘用于存储数据（RAID 0）、1块盘用于进行校验

- 校验方式：对99块数据盘的每个比特做异或、得到校验盘的每一个比特的值。

- 这样的实现，既提高了读写性能、又在一定程度上保证了数据的可靠性。但对于随机写入而言，由于每次写入都需要更新校验盘的数据，因而对校验盘的写操作很可能会成为性能瓶颈。

- RAID 5对上述问题的解决方案是：校验数据不再单独存放于一块物理盘，而是均匀分布在100块盘中。

#### fsck 和 journaling

- fsck（File System Checking）：当磁盘发生故障时，根据磁盘上已有的信息，恢复出 “最可能” 的数据结构

  - 方案1：存储实际的数据结构，这种方案是crash unsafe的

  - 方案2：Append-only记录所有历史操作。从而可以通过重做所有操作得到数据结构的当前状态，这种方式也比较容易实现崩溃一致性。

  - 二者的融合：数据结构操作发生时，用append-only记录日志，日志落盘后，用方案1更新数据结构。

- journaling：实现崩溃一致性的操作日志的追加

  - bread 定位到journal的末尾

  - bwrite 写入一个日志元数据：描述将要写入的操作日志的长度和checksum

  - bflush 等待数据落盘

  - 将数据结构操作写入实际数据结构区域

- 由于bflush容易造成性能瓶颈，目前的解决方式有：

  - jbd：jbd进程负责管理文件系统的日志功能，确保文件系统的一致性和可靠性。jbd定期write back，以减少bflush。

  - Metadata journaling(ext4 default)：数据占磁盘写入的绝大部分，因而仅对inode和bitmap做journaling可以提高性能，保证文件系统的目录结构是一致的，但数据可能丢失。